"""
A python SDK for integrating with the Duke Data Service API V1. The idea of this
sdk is centered around the idea of connecting local and remote 'Projects'. A 
'Project' for this sdk is a special term that denotes either: 
(1) specific parent-level folder on a machine (local project), or a 
(2) DDS project (remote project). 
As such, the client should implement fail-safe checks 
and enforce file system behaviors. Specifically, sub-folder names must be 
unique (DDS does not enforce this), file names within a particular folder must have 
unique names (DDS does not enfore this). We will make no assumptions when we connect 
to a DDS project and encounter a situation that breaks these rules. Instead we need 
to present the user with the issue and ask them to correct this rule violation 
through the portal if they intend on using the python sdk.
"""

class Connection(object):
    """Handles configuration and other higher level, non-project specific tasks
    with DDS.
    """
    def __init__(self,agent_credentials,store=True):
        """
        Pass in the agent credentials JSON from the portal. By default, store
        this information in config file in ~.
        :param agent_credentials: JSON/dictionary object provided by DDS portal
        :param store: boolean indicating whether to store (override) configuration file
        """
        self.attributes = 'maybe set some attributes from /current_user/usage'
    
class Project(object):
    def __init__(self,
                 remote_project_name,
                 local_project_name,
                 connection=ddsc.sdk.Connection()):
        """A project allows users to immediately tie into a specific project
        on DDS. Users should be able to go straight to this class if they've already
        stored a config file by way of ddsc.sdk.Connection.
        Raises error if DDS reports >1 project by ``project_name``.
        :param remote_project_name: The name of the project on DDSC 
        :param local_project_name: The UNC path (or filename) of the local project (folder)
        :param connection: ddsc.sdk.Connection object
        """
        self.remote_project_name = remote_project_name
        self.local_project_name = local_project_name
        self.project_id = self.get_project_id_by_name()
        
    def upload(self,provenance_only=False):
        """Uploads an entire local project - including subfolders, 
        and files from a local project to a remote project (DDS) only if discrepant hashes.
        :param provenance_only: boolean indicating if a 'fake file only' will be submitted
        :return: dictionary where key's tie into self.local_file_system_repr and values
        represent requests.Response containing the result. I really want upload to also
        upload provenance related 
        """
        if provenance_only:
            self.upload_provenance()
        else:
            self.upload_files()
            self.upload_provenance()
        
    
    def upload_provenance(self):
        """
        Some sort of mechanism to upload provenance information. Even at this level
        of sdk, some provenance can be inferred (Provenance Notes). Interestingly, other
        software that is built using this sdk, can inferr even more. Here I'm imagining
        using something like Watchdog to infer when an acitity ``was generated by`` by
        some file or some file ``used`` a particular activity. Providing a robust, easy
        way to communicate that with DDS is essential. For now, DDS doesn't allow this, so
        I'd like to include a 'hack' where fake files (import tempfile?) are 
        uploaded along with real provenance. The thought is that once I show the 
        utility of this, DDS adoption may take off."""
        pass
    
    def upload_files(self):
        """Uploads an entire local project - including subfolders, 
        and files from a local project to a remote project (DDS) only if discrepant hashes.
        """
        pass
           
    def download(self,provenance_only=False):
        """Downloads an entire folder, subfolders, and files from a local project
        to a remote project (DDS) only if discrepant hashes.
        :param provenance_only: boolean indicating if a 'fake file only' will be submitted
        :return: dictionary where key's tie into self.local_file_system_repr and values
        represent requests.Response containing the result
        """
        if provenance_only:
            self.download_provenance()
        else:
            self.download_files()
            self.download_provenance()
            
    def download_provenance(self):
        """Download provenance only. Casey is using some sort of JSON representation
        for this in the portal, maybe we can borrow"""
        pass
    
    def download_files(self):
        """Download a project's assets (folders, files) and save then to the local
        project UNC if the hashes are discrepant
        """
        pass
    
    def get_remote_repr(self):
        """
        Provide some sort of remote file system organization. One package that did something
        similar is watchdog's DirectorySnapShot (i.e. watchdog.utils.dirsnapshot.DirectorySnapShot)
        I don't think this is our solution, just an example.
        """
        pass
    
    def get_local_repr(self):
        """
        Provide some sort of remote file system organization. One package that did something
        similar is watchdog's DirectorySnapShot (i.e. watchdog.utils.dirsnapshot.DirectorySnapShot)
        I don't think this is our solution, just an example. For local, would be cool
        to see sub files and folders represented as almost 'endpoint like representation'. Where
        the superflous pre URL stuff is abstracted.
        """ 
        pass
    
    def remote_local_diff(self):
        """
        Provide an avenue to easily see which files are discrepant between remote and
        local. Might even be nice to return a dict object where there could be two
        keys: {'new_files':[],'updated_files':[]} that way when we start to auto-generate
        provenance it's easier to tie downstream versions of files to each other
        """
        pass
    
    
class Files(object):
    def __init__(self,file_name):
        """Maybe we also need a Files class whose objects could be lazy loaded into
        a Project objects attributes and we would 'compute' to get acutal results? I 
        anticipate the need to get updates about files throughout a session using
        this SDK, so it's important not to store actual information, but rather provide
        the means through which that information can be obtained reliabily and quickly
        throughout a session using this SDK.
        """
        
        
        

